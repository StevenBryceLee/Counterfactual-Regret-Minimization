{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants for Rock-Paper-Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCK = 0\n",
    "PAPER = 1\n",
    "SCISSORS = 2\n",
    "NUM_ACTIONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.3, 0.4]\n"
     ]
    }
   ],
   "source": [
    "regretSum = [0.0,0.0,0.0]\n",
    "strategy = [0.0,0.0,0.0]\n",
    "strategySum = [0.0,0.0,0.0]\n",
    "oppStrategy = [0.0,0.0,0.0]\n",
    "print(oppStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gets a strategy for a player, and adds it \n",
    "#To the normalizing Sum\n",
    "#If normalizing Sum is greater than 0, then the strategy\n",
    "#probability is divided, else the strategy is assigned\n",
    "#an equal probability to other strategies\n",
    "def getStrategy():\n",
    "    normalizingSum = 0.0\n",
    "    for x in range(NUM_ACTIONS):\n",
    "        strategy[x] = regretSum[x]  if regretSum[x] > 0 else 0\n",
    "        normalizingSum += strategy[x]\n",
    "    \n",
    "    for x in range(NUM_ACTIONS):\n",
    "        if(normalizingSum > 0):\n",
    "            strategy[x] /= normalizingSum\n",
    "        else:\n",
    "            strategy[x] = 1.0 / float(NUM_ACTIONS)\n",
    "        strategySum[x] += strategy[x]\n",
    "    return strategy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function randomly generates an action from the given\n",
    "#set of strategies with probabilities between 0 and 1\n",
    "def getAction(strategy):\n",
    "    r = float(random())\n",
    "    a = 0\n",
    "    cumulativeProbability = 0\n",
    "    while (a < NUM_ACTIONS - 1):\n",
    "        cumulativeProbability += strategy[a]\n",
    "        if ( r < cumulativeProbability):\n",
    "            break\n",
    "        a += 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the training algorithm\n",
    "#It accepts the desired number of iterations\n",
    "#For the number of iterations, compute regret-matched\n",
    "#mixed strategy actions, utilities, and accumulate regrets\n",
    "def train(iterations):\n",
    "    actionUtility = [0.0,0.0,0.0]\n",
    "    for i in range(iterations):\n",
    "        #Get regret-matched mixed-strategy actions\n",
    "        Strategy = getStrategy()\n",
    "        myAction = getAction(strategy)\n",
    "        otherAction = getAction(oppStrategy)\n",
    "        #compute action utilities\n",
    "        actionUtility[otherAction] = float(0)\n",
    "        actionUtility[0 if (otherAction == NUM_ACTIONS - 1) else otherAction + 1] = 1\n",
    "        actionUtility[NUM_ACTIONS - 1 if (otherAction == 0) else otherAction - 1] = -1\n",
    "        #Accumulate action regrets\n",
    "        #This is the difference between an action's expected utility\n",
    "        #and the actual utility\n",
    "        #This is then added to the cumulative regrets\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            regretSum[a] += actionUtility[a] - actionUtility[myAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function gets the average strategy across all \n",
    "#training iterations. This prevents skew from any\n",
    "#sub-optimal strategy from dominating\n",
    "def getAverageStrategy():\n",
    "    avgStrategy = [0.0,0.0,0.0]\n",
    "    normalizingSum = float(0)\n",
    "    for a in range(NUM_ACTIONS):\n",
    "        normalizingSum += strategySum[a]\n",
    "    for a in range(NUM_ACTIONS):\n",
    "        if (normalizingSum > 0):\n",
    "            avgStrategy[a] = strategySum[a] / normalizingSum\n",
    "        else:\n",
    "            avgStrategy[a] = 1.0 / NUM_ACTIONS\n",
    "    return avgStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999955402380952, 4.393095238095237e-06, 6.666666666666667e-08]\n"
     ]
    }
   ],
   "source": [
    "train(10000000)\n",
    "print(getAverageStrategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class player:\n",
    "    getAverageStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
